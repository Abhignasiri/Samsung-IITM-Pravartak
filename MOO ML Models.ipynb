{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More automated Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdataset(n):\n",
    "    global test_data_points\n",
    "    if (n==1):\n",
    "        test_data_points= [6,10,14,15,20,22,29,32,37,42,48,54,56,61,62,67,68,72,81,86,90,96,101,102,104,105,111,122,123]\n",
    "    if (n==2):\n",
    "        test_data_points= [1,2,9,23,28,31,36,39,40,41,43,53,57,70,73,74,78,80,82,85,91,98,109,110,113,116,119,121,125]\n",
    "    if (n==3):\n",
    "        test_data_points= [4,5,18,19,24,28,33,34,35,36,38,47,49,51,53,58,59,63,66,69,78,84,89,93,97,98,113,120,121]\n",
    "    if (n==4):\n",
    "        test_data_points= [13,17,19,21,25,26,28,30,39,41,43,46,50,52,59,64,65,66,70,77,82,85,89,91,95,98,110,114,121]\n",
    "    if (n==5):\n",
    "        test_data_points= [2,4,9,28,30,31,35,39,40,43,45,50,52,53,55,63,66,70,73,77,87,89,91,93,100,115,116,120,125]\n",
    "    if (n==6):\n",
    "        test_data_points= [2,5,13,16,17,21,25,28,34,38,39,41,43,45,47,57,65,74,77,78,79,87,95,103,107,112,114,116,119]\n",
    "    if (n==7):\n",
    "        test_data_points= [5,7,8,12,13,16,23,26,27,33,40,44,47,51,53,55,57,69,70,71,78,82,89,91,92,103,110,114,120]\n",
    "    if (n==8):\n",
    "        test_data_points= [5,11,13,21,23,26,28,30,36,40,46,51,55,64,66,71,74,85,87,94,95,106,107,109,110,112,113,117,118]\n",
    "    if (n==9):\n",
    "        test_data_points= [9,25,27,31,34,35,36,46,53,59,64,75,76,78,79,80,82,84,85,89,94,106,107,108,112,113,116,118,124]\n",
    "    if (n==10):\n",
    "        test_data_points= [1,7,21,23,26,31,36,44,50,58,59,69,73,79,83,88,89,98,99,103,107,108,109,113,116,120,121,124,125]\n",
    "    #return test_data_points\n",
    "\n",
    "def algorithm(k):\n",
    "    algo[k-1].fit(x_train,y_train)\n",
    "    pred_test=algo[k-1].predict(x_test)\n",
    "    pred_train=algo[k-1].predict(x_train)\n",
    "    \n",
    "    na.append(name[k-1]+'train')\n",
    "    na.append(name[k-1]+'test')\n",
    "    \n",
    "    #mean squared error\n",
    "    msetrain = mean_squared_error(y_train, pred_train)\n",
    "    msetrain = np.sqrt(msetrain)\n",
    "    mse.append(msetrain)\n",
    "    msetest = mean_squared_error(y_test,pred_test)\n",
    "    msetest = np.sqrt(msetest)\n",
    "    mse.append(msetest)\n",
    "    \n",
    "    #mean absolute error\n",
    "    maetrain = mean_absolute_error(y_train, pred_train)\n",
    "    mae.append(maetrain)\n",
    "    maetest = mean_absolute_error(y_test,pred_test)\n",
    "    mae.append(maetest)\n",
    "    \n",
    "    #r2 score\n",
    "    r2train = r2_score(y_train, pred_train)\n",
    "    r2.append(r2train)\n",
    "    r2test = r2_score(y_test,pred_test)\n",
    "    r2.append(r2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "a1=ExtraTreesRegressor(max_depth=5, min_samples_leaf=35, min_samples_split=20, n_estimators=30, n_jobs=4, random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "a2=LinearRegression()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "a3=DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "a4=RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "a5=KNeighborsRegressor(n_neighbors=4)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "a6=GradientBoostingRegressor(max_depth=4, n_estimators=67, learning_rate=0.11, random_state=42)\n",
    "import xgboost\n",
    "a7=xgboost.XGBRegressor()\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "a8=MLPRegressor(random_state=1, max_iter=1000)\n",
    "from sklearn import linear_model\n",
    "a9=linear_model.Lasso(alpha=0.1)\n",
    "from sklearn.linear_model import Ridge\n",
    "a10=Ridge(alpha=1.0)\n",
    "from sklearn.svm import SVC\n",
    "a11=SVC(gamma=0.1, C=2)\n",
    "\n",
    "algo=[a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11]\n",
    "name=['ExtraTreesRegressor','LinearRegression','DecisionTreeRegressor','RandomForestRegressor','KNeighborsRegressor','GradientBoostingRegressor','XGBRegressor','MLPRegressor','Lasso','Ridge','SVM']\n",
    "\n",
    "mse=[]\n",
    "mae=[]\n",
    "r2=[]\n",
    "na=[]\n",
    "\n",
    "loc = (\"Training data 125.xlsx\")\n",
    "tot=pd.read_excel(loc,sheet_name='Total data')\n",
    "\n",
    "j=input('Black/Paradiso/Rawsilk?:')\n",
    "if (j=='Black'):\n",
    "    df=tot.drop(['Black','Paradiso','Rawsilk','Paradisom','Rawsilkm','power (J/s)'],axis=1)\n",
    "if (j=='Paradiso'):\n",
    "    df=tot.drop(['Black','Paradiso','Rawsilk','Blackm','Rawsilkm','power (J/s)'],axis=1)\n",
    "if (j=='Rawsilk'):\n",
    "    df=tot.drop(['Black','Paradiso','Rawsilk','Paradisom','Blackm','power (J/s)'],axis=1)\n",
    "print (df.head())\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for i in range(1,5):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df.iloc[:,i])\n",
    "    df.iloc[:,i] = le.transform(df.iloc[:,i])\n",
    "\n",
    "while True:\n",
    "    p=int(input('\\n Choose dataset from 1 to 10:'))\n",
    "    testdataset(p)\n",
    "\n",
    "    df=df.astype({'S. No.':int})\n",
    "    train_data=df[~df['S. No.'].isin(test_data_points)]\n",
    "    test_data=df[df['S. No.'].isin(test_data_points)]\n",
    "\n",
    "    train_data1=train_data.drop(['S. No.'],axis=1)\n",
    "    test_data1 = test_data.drop(['S. No.'],axis=1)\n",
    "\n",
    "    if (j=='Black'):\n",
    "        x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "        y_train = train_data1['Blackm']\n",
    "        x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "        y_test = test_data1['Blackm']\n",
    "    if (j=='Paradiso'):\n",
    "        x_train = train_data1.drop(['Paradisom'],axis=1)\n",
    "        y_train = train_data1['Paradisom']\n",
    "        x_test = test_data1.drop(['Paradisom'],axis=1)\n",
    "        y_test = test_data1['Paradisom']\n",
    "    if (j=='Rawsilk'):\n",
    "        x_train = train_data1.drop(['Rawsilkm'],axis=1)\n",
    "        y_train = train_data1['Rawsilkm']\n",
    "        x_test = test_data1.drop(['Rawsilkm'],axis=1)\n",
    "        y_test = test_data1['Rawsilkm']\n",
    "\n",
    "    for u in range(1,12):\n",
    "        algorithm(u)\n",
    "    set1=list(zip(na,mse,mae,r2))\n",
    "    dff=pd.DataFrame(set1,columns=['Algorithm','mse','mae','r2'])\n",
    "    print(dff)\n",
    "\n",
    "    d=input(\"\\n want to check for artificial? enter 'y' or 'n':\")\n",
    "    if (d=='y'):\n",
    "        bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "        grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "        grid_search.fit(train_data1)\n",
    "        kde = grid_search.best_estimator_\n",
    "        new_data = kde.sample(40, random_state=42)\n",
    "        new_data=pd.DataFrame(new_data)\n",
    "        \n",
    "        if (j=='Black'):\n",
    "            new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Blackm']\n",
    "        if (j=='Paradiso'):\n",
    "            new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Paradisom']\n",
    "        if (j=='Rawsilk'):\n",
    "            new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Rawsilkm']\n",
    "\n",
    "        train_data2 = pd.concat([train_data1,new_data])\n",
    "        \n",
    "        if (j=='Black'):\n",
    "            x_train = train_data2.drop(['Blackm'],axis=1)\n",
    "            y_train = train_data2['Blackm']\n",
    "            x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "            y_test = test_data1['Blackm']\n",
    "        if (j=='Paradiso'):\n",
    "            x_train = train_data2.drop(['Paradisom'],axis=1)\n",
    "            y_train = train_data2['Paradisom']\n",
    "            x_test = test_data1.drop(['Paradisom'],axis=1)\n",
    "            y_test = test_data1['Paradisom']\n",
    "        if (j=='Rawsilk'):\n",
    "            x_train = train_data2.drop(['Rawsilkm'],axis=1)\n",
    "            y_train = train_data2['Rawsilkm']\n",
    "            x_test = test_data1.drop(['Rawsilkm'],axis=1)\n",
    "            y_test = test_data1['Rawsilkm']\n",
    "\n",
    "        na.clear()\n",
    "        mse.clear()\n",
    "        mae.clear()\n",
    "        r2.clear()\n",
    "\n",
    "        for v in range(1,11):\n",
    "            algorithm(v)\n",
    "        set2=list(zip(na,mse,mae,r2))\n",
    "        dfa=pd.DataFrame(set2,columns=['Algorithm','mse','mae','r2'])\n",
    "        print(dfa)\n",
    "        \n",
    "    o=input(\"\\n want to check for another dataset?: enter 'y' or 'n':\")\n",
    "    if (o=='y'):\n",
    "        na.clear()\n",
    "        mse.clear()\n",
    "        mae.clear()\n",
    "        r2.clear()\n",
    "    if (o=='n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-automated Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdataset(n):        #run -  test_data_points=testdataset(1)\n",
    "    global test_data_points\n",
    "    if (n==1):\n",
    "        test_data_points= [6,10,14,15,20,22,29,32,37,42,48,54,56,61,62,67,68,72,81,86,90,96,101,102,104,105,111,122,123]\n",
    "    if (n==2):\n",
    "        test_data_points= [1,2,9,23,28,31,36,39,40,41,43,53,57,70,73,74,78,80,82,85,91,98,109,110,113,116,119,121,125]\n",
    "    if (n==3):\n",
    "        test_data_points= [4,5,18,19,24,28,33,34,35,36,38,47,49,51,53,58,59,63,66,69,78,84,89,93,97,98,113,120,121]\n",
    "    if (n==4):\n",
    "        test_data_points= [13,17,19,21,25,26,28,30,39,41,43,46,50,52,59,64,65,66,70,77,82,85,89,91,95,98,110,114,121]\n",
    "    if (n==5):\n",
    "        test_data_points= [2,4,9,28,30,31,35,39,40,43,45,50,52,53,55,63,66,70,73,77,87,89,91,93,100,115,116,120,125]\n",
    "    if (n==6):\n",
    "        test_data_points= [2,5,13,16,17,21,25,28,34,38,39,41,43,45,47,57,65,74,77,78,79,87,95,103,107,112,114,116,119]\n",
    "    if (n==7):\n",
    "        test_data_points= [5,7,8,12,13,16,23,26,27,33,40,44,47,51,53,55,57,69,70,71,78,82,89,91,92,103,110,114,120]\n",
    "    if (n==8):\n",
    "        test_data_points= [5,11,13,21,23,26,28,30,36,40,46,51,55,64,66,71,74,85,87,94,95,106,107,109,110,112,113,117,118]\n",
    "    if (n==9):\n",
    "        test_data_points= [9,25,27,31,34,35,36,46,53,59,64,75,76,78,79,80,82,84,85,89,94,106,107,108,112,113,116,118,124]\n",
    "    if (n==10):\n",
    "        test_data_points= [1,7,21,23,26,31,36,44,50,58,59,69,73,79,83,88,89,98,99,103,107,108,109,113,116,120,121,124,125]\n",
    "    #return test_data_points\n",
    "\n",
    "def algorithm(k):\n",
    "    algo[k-1].fit(x_train,y_train)\n",
    "    pred_test=algo[k-1].predict(x_test)\n",
    "    pred_train=algo[k-1].predict(x_train)\n",
    "    \n",
    "    #mean squared error\n",
    "    msetrain = mean_squared_error(y_train, pred_train)\n",
    "    msetrain = np.sqrt(msetrain)\n",
    "    print(\"Mean squared error train:\",msetrain)\n",
    "    msetest = mean_squared_error(y_test,pred_test)\n",
    "    msetest = np.sqrt(msetest)\n",
    "    print(\"Mean squared error test:\",msetest)\n",
    "    \n",
    "    #mean absolute error\n",
    "    maetrain = mean_absolute_error(y_train, pred_train)\n",
    "    print(\"Mean absolute error train:\",maetrain)\n",
    "    maetest = mean_absolute_error(y_test,pred_test)\n",
    "    print(\"Mean absolute error test:\",maetest)\n",
    "    \n",
    "    #r2 score\n",
    "    r2train = r2_score(y_train, pred_train)\n",
    "    print(\"r2 score train:\",r2train)\n",
    "    r2test = r2_score(y_test,pred_test)\n",
    "    print(\"r2 score test:\",r2test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with label encoding approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "loc = (\"Training data 125.xlsx\")\n",
    "tot=pd.read_excel(loc,sheet_name='Total data')\n",
    "df=tot.drop(['Black','Paradiso','Rawsilk','Paradisom','Rawsilkm','power (J/s)'],axis=1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for i in range(1,5):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df.iloc[:,i])\n",
    "    df.iloc[:,i] = le.transform(df.iloc[:,i])\n",
    "    \n",
    "p=int(input('Choose dataset from 1 to 10:'))\n",
    "testdataset(p)\n",
    "\n",
    "df=df.astype({'S. No.':int})\n",
    "train_data=df[~df['S. No.'].isin(test_data_points)]\n",
    "test_data=df[df['S. No.'].isin(test_data_points)]\n",
    "\n",
    "train_data1=train_data.drop(['S. No.'],axis=1)\n",
    "test_data1 = test_data.drop(['S. No.'],axis=1)\n",
    "\n",
    "x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "y_train = train_data1['Blackm']\n",
    "x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "y_test = test_data1['Blackm']\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "a1=ExtraTreesRegressor(max_depth=5, min_samples_leaf=35, min_samples_split=20, n_estimators=30, n_jobs=4, random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "a2=LinearRegression()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "a3=DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "a4=RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "a5=KNeighborsRegressor(n_neighbors=4)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "a6=GradientBoostingRegressor(max_depth=4, n_estimators=67, learning_rate=0.11, random_state=42)\n",
    "import xgboost\n",
    "a7=xgboost.XGBRegressor()\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "a8=MLPRegressor(random_state=1, max_iter=1000)\n",
    "from sklearn import linear_model\n",
    "a9=linear_model.Lasso(alpha=0.1)\n",
    "from sklearn.linear_model import Ridge\n",
    "a10=Ridge(alpha=1.0)\n",
    "from sklearn.svm import SVC\n",
    "a11=SVC(gamma=0.1, C=2)\n",
    "\n",
    "algo=[a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11]\n",
    "\n",
    "while True:\n",
    "    t=int(input(\"\\n choose algorithms from 1 to 11: (1-Extra Trees, 2-Linear Regression, 3-Decision Trees, 4-Random Forest Regressor, 5-KNN, 6-Gradient Boost, 7-XGBoost, 8-Neural Networks, 9-Lasso Regression, 10-Ridge Regression, 11-Support Vector Machines)\"))\n",
    "    algorithm(t)\n",
    "    g=input(\"\\n want to check for another algorithm with same dataset? enter 'y' or 'n':\")\n",
    "    if (g=='n'):\n",
    "        break\n",
    "\n",
    "d=input(\"\\n want to check for artificial? enter 'y' or 'n':\")\n",
    "if (d=='y'):\n",
    "    bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "    grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "    grid_search.fit(train_data1)\n",
    "    kde = grid_search.best_estimator_\n",
    "    new_data = kde.sample(40, random_state=42)\n",
    "    new_data=pd.DataFrame(new_data)\n",
    "    new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Blackm']\n",
    "    train_data1 = pd.concat([train_data1,new_data])\n",
    "    x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "    y_train = train_data1['Blackm']\n",
    "    x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "    y_test = test_data1['Blackm']\n",
    "        \n",
    "    while True:\n",
    "        t=int(input(\"\\n choose algorithms from 1 to 11: (1-Extra Trees, 2-Linear Regression, 3-Decision Trees, 4-Random Forest Regressor, 5-KNN, 6-Gradient Boost, 7-XGBoost, 8-Neural Networks, 9-Lasso Regression, 10-Ridge Regression, 11-Support Vector Machines)\"))\n",
    "        algorithm(t)\n",
    "        g=input(\"\\n want to check for another algorithm with same dataset with artificial data? enter 'y' or 'n':\")\n",
    "        if (g=='n'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort_values ordering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "loc = (\"Training data 125.xlsx\")\n",
    "tot=pd.read_excel(loc,sheet_name='Total data')\n",
    "df=tot.drop(['Black','Paradiso','Rawsilk','Paradisom','Rawsilkm','power (J/s)'],axis=1)\n",
    "\n",
    "data=df\n",
    "for feature in data.columns:\n",
    "    labels_ordered=data.groupby([feature])['Blackm'].mean().sort_values().index\n",
    "    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n",
    "    data[feature]=data[feature].map(labels_ordered)\n",
    "    \n",
    "p=int(input('Choose dataset from 1 to 10:'))\n",
    "testdataset(p)\n",
    "\n",
    "df=df.astype({'S. No.':int})\n",
    "train_data=df[~df['S. No.'].isin(test_data_points)]\n",
    "test_data=df[df['S. No.'].isin(test_data_points)]\n",
    "\n",
    "train_data1=train_data.drop(['S. No.'],axis=1)\n",
    "test_data1 = test_data.drop(['S. No.'],axis=1)\n",
    "\n",
    "x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "y_train = train_data1['Blackm']\n",
    "x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "y_test = test_data1['Blackm']\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "a1=ExtraTreesRegressor(max_depth=5, min_samples_leaf=35, min_samples_split=20, n_estimators=30, n_jobs=4, random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "a2=LinearRegression()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "a3=DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "a4=RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "a5=KNeighborsRegressor(n_neighbors=4)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "a6=GradientBoostingRegressor(max_depth=4, n_estimators=67, learning_rate=0.11, random_state=42)\n",
    "import xgboost\n",
    "a7=xgboost.XGBRegressor()\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "a8=MLPRegressor(random_state=1, max_iter=1000)\n",
    "from sklearn import linear_model\n",
    "a9=linear_model.Lasso(alpha=0.1)\n",
    "from sklearn.linear_model import Ridge\n",
    "a10=Ridge(alpha=1.0)\n",
    "from sklearn.svm import SVC\n",
    "a11=SVC(gamma=0.1, C=2)\n",
    "\n",
    "algo=[a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11]\n",
    "\n",
    "while True:\n",
    "    t=int(input(\"\\n choose algorithms from 1 to 11: (1-Extra Trees, 2-Linear Regression, 3-Decision Trees, 4-Random Forest Regressor, 5-KNN, 6-Gradient Boost, 7-XGBoost, 8-Neural Networks, 9-Lasso Regression, 10-Ridge Regression, 11-Support Vector Machines)\"))\n",
    "    algorithm(t)\n",
    "    g=input(\"\\n want to check for another algorithm with same dataset? enter 'y' or 'n':\")\n",
    "    if (g=='n'):\n",
    "        break\n",
    "\n",
    "d=input(\"\\n want to check for artificial? enter 'y' or 'n':\")\n",
    "if (d=='y'):\n",
    "    bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "    grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "    grid_search.fit(train_data1)\n",
    "    kde = grid_search.best_estimator_\n",
    "    new_data = kde.sample(40, random_state=42)\n",
    "    new_data=pd.DataFrame(new_data)\n",
    "    new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Blackm']\n",
    "    train_data1 = pd.concat([train_data1,new_data])\n",
    "    x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "    y_train = train_data1['Blackm']\n",
    "    x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "    y_test = test_data1['Blackm']\n",
    "        \n",
    "    while True:\n",
    "        t=int(input(\"\\n choose algorithms from 1 to 11: (1-Extra Trees, 2-Linear Regression, 3-Decision Trees, 4-Random Forest Regressor, 5-KNN, 6-Gradient Boost, 7-XGBoost, 8-Neural Networks, 9-Lasso Regression, 10-Ridge Regression, 11-Support Vector Machines)\"))\n",
    "        algorithm(t)\n",
    "        g=input(\"\\n want to check for another algorithm with same dataset with artificial data? enter 'y' or 'n':\")\n",
    "        if (g=='n'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### rough work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "loc = (\"Training data 125.xlsx\")\n",
    "tot=pd.read_excel(loc,sheet_name='Total data')\n",
    "df=tot.drop(['Black','Paradiso','Rawsilk','Paradisom','Rawsilkm','power (J/s)'],axis=1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for i in range(1,5):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df.iloc[:,i])\n",
    "    df.iloc[:,i] = le.transform(df.iloc[:,i])\n",
    "    \n",
    "testdataset(1)\n",
    "\n",
    "df=df.astype({'S. No.':int})\n",
    "train_data=df[~df['S. No.'].isin(test_data_points)]\n",
    "test_data=df[df['S. No.'].isin(test_data_points)]\n",
    "\n",
    "train_data1=train_data.drop(['S. No.'],axis=1)\n",
    "test_data1 = test_data.drop(['S. No.'],axis=1)\n",
    "\n",
    "x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "y_train = train_data1['Blackm']\n",
    "x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "y_test = test_data1['Blackm']\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "a=SVC(gamma=0.1, C=2)\n",
    "a.fit(x_train,y_train)\n",
    "pred_test=a.predict(x_test)\n",
    "pred_train=a.predict(x_train)\n",
    "    \n",
    "    #mean squared error\n",
    "msetrain = mean_squared_error(y_train, pred_train)\n",
    "msetrain = np.sqrt(msetrain)\n",
    "print(\"Mean squared error train:\",msetrain)\n",
    "msetest = mean_squared_error(y_test,pred_test)\n",
    "msetest = np.sqrt(msetest)\n",
    "print(\"Mean squared error test:\",msetest)\n",
    "    \n",
    "    #mean absolute error\n",
    "maetrain = mean_absolute_error(y_train, pred_train)\n",
    "print(\"Mean absolute error train:\",maetrain)\n",
    "maetest = mean_absolute_error(y_test,pred_test)\n",
    "print(\"Mean absolute error test:\",maetest)\n",
    "    \n",
    "    #r2 score\n",
    "r2train = r2_score(y_train, pred_train)\n",
    "print(\"r2 score train:\",r2train)\n",
    "r2test = r2_score(y_test,pred_test)\n",
    "print(\"r2 score test:\",r2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth_params = {'bandwidth': np.arange(0.01,1,0.05)}\n",
    "grid_search = GridSearchCV(KernelDensity(), bandwidth_params)\n",
    "grid_search.fit(train_data1)\n",
    "kde = grid_search.best_estimator_\n",
    "new_data = kde.sample(40, random_state=42)\n",
    "new_data=pd.DataFrame(new_data)\n",
    "new_data.columns=['Waterjet Pressure (Mpa)','Jet Traverse rate (mm/min)','Abrasive mass flow rate (kg/min)','Blackm']\n",
    "train_data1 = pd.concat([train_data1,new_data])\n",
    "x_train = train_data1.drop(['Blackm'],axis=1)\n",
    "y_train = train_data1['Blackm']\n",
    "x_test = test_data1.drop(['Blackm'],axis=1)\n",
    "y_test = test_data1['Blackm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "a=SVC(gamma=0.1, C=2)\n",
    "a.fit(x_train,y_train)\n",
    "pred_test=a.predict(x_test)\n",
    "pred_train=a.predict(x_train)\n",
    "\n",
    "#mean squared error\n",
    "msetrain = mean_squared_error(y_train, pred_train)\n",
    "msetrain = np.sqrt(msetrain)\n",
    "print(\"Mean squared error train:\",msetrain)\n",
    "msetest = mean_squared_error(y_test,pred_test)\n",
    "msetest = np.sqrt(msetest)\n",
    "print(\"Mean squared error test:\",msetest)\n",
    "    \n",
    "    #mean absolute error\n",
    "maetrain = mean_absolute_error(y_train, pred_train)\n",
    "print(\"Mean absolute error train:\",maetrain)\n",
    "maetest = mean_absolute_error(y_test,pred_test)\n",
    "print(\"Mean absolute error test:\",maetest)\n",
    "    \n",
    "    #r2 score\n",
    "r2train = r2_score(y_train, pred_train)\n",
    "print(\"r2 score train:\",r2train)\n",
    "r2test = r2_score(y_test,pred_test)\n",
    "print(\"r2 score test:\",r2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
